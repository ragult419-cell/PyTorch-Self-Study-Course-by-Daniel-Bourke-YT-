{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9OmULyNhvB2gGKdKhnk4+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VXNw6sijX33a"},"outputs":[],"source":["import torch\n","from torch import nn\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Project 1 - Linear classifier\n","# y = mx + b, where m is weight and b is bias\n","\n","# Create known parameters\n","weight = 0.7\n","bias = 0.3\n","\n","# Create\n","start = 0\n","end = 1\n","step = 0.02\n","X = torch.arange(start, end, step).unsqueeze(dim = 1)\n","Y = weight * X + bias\n","\n","X[:10], Y[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFwyfAptZoZV","executionInfo":{"status":"ok","timestamp":1757524663918,"user_tz":240,"elapsed":103,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"5ee24219-0f1a-46cf-a401-33e86fc01026"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[0.0000],\n","         [0.0200],\n","         [0.0400],\n","         [0.0600],\n","         [0.0800],\n","         [0.1000],\n","         [0.1200],\n","         [0.1400],\n","         [0.1600],\n","         [0.1800]]),\n"," tensor([[0.3000],\n","         [0.3140],\n","         [0.3280],\n","         [0.3420],\n","         [0.3560],\n","         [0.3700],\n","         [0.3840],\n","         [0.3980],\n","         [0.4120],\n","         [0.4260]]))"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Create a train/test split\n","# 80% data for training, remaining 20% for testing. No validation in this simple model\n","train_split = int(.8 * len(X))\n","X_train = X[:train_split]\n","X_test = X[train_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:]\n","\n","len(X_train), len(Y_train), len(X_test), len(Y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fgYAaIsauC1","executionInfo":{"status":"ok","timestamp":1757524663936,"user_tz":240,"elapsed":15,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"f699d6e9-3c8b-49a8-9220-4cf451c26e79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40, 40, 10, 10)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Create linear regression model class\n","class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherits from nn.Module\n","  def __init__(self):\n","    super().__init__()\n","    self.weights = nn.Parameter(torch.randn((1,), # <- start with a random weight and try to adjust it to the ideal weight\n","                                            requires_grad=True, # <- can this parameter be updated through gradient descent?\n","                                            dtype=torch.float)) # <- Python loves the data type torch.float.32\n","\n","    self.bias = nn.Parameter(torch.randn((1,), # <- start with a random bias and try to adjust it to the ideal weight\n","                                         requires_grad=True, # <- can this parameter be updated through gradient descent?\n","                                         dtype=torch.float)) # <- Python loves the data type torch.float.32\n","\n","  # Forward method to define the computation in the model\n","  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n","    return self.weights * x + self.bias # this is the linear regression formula"],"metadata":{"id":"YyKE3r6acGrp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Building Essentials\n","\n","* torch.nn - contains all of the building for computational graphs ( a neural network can be considered a computational graph)\n","* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set this for us.\n","* torch.nn.Module - The base class for all neural network models, if you subclass it, you should overwrite forward()\n","* torch.optim - this is where the optimizers in Pytorch live, they will help with gradient descent.\n","* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation."],"metadata":{"id":"ftm4DFWHe6MF"}},{"cell_type":"markdown","source":["### Checking the contents of our PyTorch model\n","Now we've created a model, lets see whats inside:\n","So we can check our model parameters or whats inside our module using ,parameters()."],"metadata":{"id":"AsohuqCbg2F8"}},{"cell_type":"code","source":["# Create a random seed\n","torch.manual_seed(39)\n","\n","# Create an instance of the model (this is a subclass of nn.Module)\n","model_0 = LinearRegressionModel()\n","\n","# Check out the parameters\n","list(model_0.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpJTSN1_ex6P","executionInfo":{"status":"ok","timestamp":1757524663952,"user_tz":240,"elapsed":14,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"1b3706d2-0ae0-4e9d-da6f-b4871b5e244a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([0.4447], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.0819], requires_grad=True)]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# List named parameters\n","model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RxtvbA6jNPQ","executionInfo":{"status":"ok","timestamp":1757524663957,"user_tz":240,"elapsed":4,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"cc6471e6-760f-4251-ca7f-f6e1de46d1c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.4447])), ('bias', tensor([0.0819]))])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["weight, bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0x0Cwn2ojTHv","executionInfo":{"status":"ok","timestamp":1757524663970,"user_tz":240,"elapsed":3,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"6f1df30d-1151-4dfc-ba2a-ee7636163d4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.7, 0.3)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Making prediction using 'torch.inference_model()'\n","\n","To check our model's predictive power, let's see how well it predicts 'y_test' based on 'X_test'.\n","\n","When we pass data through our model, it's going to run it through the 'forward()' method.'"],"metadata":{"id":"iHE0-U86jjSe"}},{"cell_type":"code","source":[],"metadata":{"id":"rKWJS3DYQkO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions with model\n","with torch.no_grad():\n","  y_preds = model_0(X_test)\n","\n","y_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zy5PTQAUkQd_","executionInfo":{"status":"ok","timestamp":1757524664001,"user_tz":240,"elapsed":5,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"b065089d-c52f-42c2-c88c-2dd494fedf7e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4377],\n","        [0.4466],\n","        [0.4555],\n","        [0.4644],\n","        [0.4733],\n","        [0.4822],\n","        [0.4911],\n","        [0.5000],\n","        [0.5089],\n","        [0.5177]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Classes in Python\n","# Great for reusability\n","# Functions perform actions; classes define blueprints for objects that encapsulate data and actions.\n","class Pet:\n","  def __init__(self, name, species):\n","    self.name = name\n","    self.species = species\n","\n","  def introduce(self):\n","    print(f\"Hello, my name is {self.name} and I am a {self.species}.\")\n","\n","dog = Pet(name=\"Buddy\", species=\"Dog\")\n","\n"],"metadata":{"id":"N6dRQ96ILQ1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dog.introduce()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6lph7IwM21N","executionInfo":{"status":"ok","timestamp":1757524664005,"user_tz":240,"elapsed":5,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"8bf8c3a2-eb91-4322-bc7c-7cebb0001cdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, my name is Buddy and I am a Dog.\n"]}]},{"cell_type":"code","source":["# Can add an attribute not in original class as well\n","\n","dog.color = \"Brown\"\n","dog.color"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UCbP3yGIN3my","executionInfo":{"status":"ok","timestamp":1757524664008,"user_tz":240,"elapsed":3,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"5851eb9b-f893-48da-ce27-73470eb9ea53"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Brown'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### Train Model\n","\n","The whole idea of training is for a model to move from some unknown parameters to some known paramters.\n","\n","In other words, from a poor representation to a better representation of data.\n","\n","One way to measure how poor or how wrong your models predictions are is to use a loss function.\n","\n","**Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n","\n","**Optimizer** Takes into account the loss of a model and adjusts the model's parameters (eg weight & bias) to improve loss function.\n","\n","Inside the optimizer you'll often have to set two parameters:\n","- params - the model parameters you'd like to optimize, for example params = model_0.parameters()\n","- lr (learning rate) - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small lr results in small changes, a large lr results in large changes)\n","\n","For Pytorch specifically, we need:\n","- A Training Loop\n","- A Testing Loop\n","\n","Lots of loss functions on Pytorch with specific syntax\n","\n","**Mean Absolute Error (MAE)\n","- abs diff of predicted and actual result of one point and then the mean of the entire range is the MAE"],"metadata":{"id":"KiHXOjMDQmB3"}},{"cell_type":"code","source":["model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4B2WMwTjSAln","executionInfo":{"status":"ok","timestamp":1757524664024,"user_tz":240,"elapsed":15,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"83218026-5727-4536-9e21-fdb6a72b8202"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.4447])), ('bias', tensor([0.0819]))])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Setup a loss function - measures how wrong our function is\n","loss_fn = nn.L1Loss()\n","\n","# Setup an optimizer (stochastic gradient descent) - adjusts parameters to minimize loss\n","optimizer = torch.optim.SGD(params=model_0.parameters(),\n","                            lr=0.01) # lr = learning rate = possibly the most important hyperparameter you can set\n"],"metadata":{"id":"bBCEPaAyV4wL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q**: Which loss function and optimizer should i use?\n","\n","**A**: This will be problem specific. But with experience, you'll get an idea of what works and what doesn't with your particular problem set.\n","\n","For example, for a regression problem (like ours), a loss function of nn.L1Loss() and an optimizer like torch.optim.SGD() will suffice.\n","\n","But for classification problems like classifying whether a photo is of a dog or cat, you'll likely want to use a loss function of nn.BCELoss() (binary cross entropy loss)\n"],"metadata":{"id":"-MGrwfltYIpV"}},{"cell_type":"markdown","source":["### Building a training loop (and a testing loop) in PyTorch\n","\n","A couple of things we need in a training loop:\n","\n","0. Loop through the data\n","1. Forward pass (this involves data moving through our model's 'forward()' functions) to make predictions on data - also called forward propogation\n","2. Calculate the loss (compare forward pass predictions to ground truth labels)\n","3. Optimizer zero grad\n","4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropagation**)\n","5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**Gradient Descent**)\n"],"metadata":{"id":"0cUOHf3jZSAC"}},{"cell_type":"code","source":["list(model_0.parameters())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mewdCaU6bbSQ","executionInfo":{"status":"ok","timestamp":1757524668720,"user_tz":240,"elapsed":6,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"5fce56a6-a2a8-48a9-ea2b-df1459558f6c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([0.4447], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.0819], requires_grad=True)]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["torch.manual_seed(39)\n","\n","# An epoch is one loop through the data... (this is a hyperparameter since we set it ourselves)\n","epochs = 100\n","\n","# Track diffeerent values\n","epoch_count = []\n","loss_values = []\n","test_loss_values = []\n","\n","### Training\n","# 0. Loop through the data\n","for epoch in range (epochs):\n","  # Set the model to training mode\n","  model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n","\n","  # 1. Forward pass\n","  y_pred = model_0(X_train)\n","\n","  # 2. Calculate the loss\n","  loss = loss_fn(y_pred, Y_train)\n","\n","  # 3. Optimizer zero grad (Zero to start fresh each forward path)\n","  optimizer.zero_grad()\n","\n","  # 4. Perform backpropagation on the loss with respect to the parameters of the model\n","  loss.backward()\n","\n","  # 5. Step the optimizer (perform gradient descent)\n","  optimizer.step() # by default how the optimizer changes will accumulate through the loop so... we have to zero them above in step 3 for the next iteration of the loop.\n","\n","\n","### Testing\n","  model_0.eval() # turns off different settings in the model not needed for evaluation/testing (drop out/Batch Norm)\n","  with torch.inference_mode(): # turns off gradient tracking & a couple more things behind the scene\n","  # 1. Do the forward pass\n","   test_pred = model_0(X_test)\n","\n","  # 2. Calculate the loss\n","   test_loss = loss_fn(test_pred, Y_test)\n","\n","# Print what's happening\n","  if epoch%10 == 0:\n","    epoch_count.append(epoch)\n","    loss_values.append(loss)\n","    test_loss_values.append(test_loss)\n","    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss: {test_loss}\")"],"metadata":{"id":"K-intm0lbaLB","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1757524668797,"user_tz":240,"elapsed":77,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"d4f2470a-139f-4b64-9e0f-fa89eedcba66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Loss: 0.31763267517089844 | Test loss: 0.43180543184280396\n","Epoch: 10 | Loss: 0.20242269337177277 | Test loss: 0.29709547758102417\n","Epoch: 20 | Loss: 0.08721272647380829 | Test loss: 0.16238555312156677\n","Epoch: 30 | Loss: 0.029277771711349487 | Test loss: 0.07662559300661087\n","Epoch: 40 | Loss: 0.024191657081246376 | Test loss: 0.05686289072036743\n","Epoch: 50 | Loss: 0.02073388360440731 | Test loss: 0.04790344834327698\n","Epoch: 60 | Loss: 0.01730123721063137 | Test loss: 0.03963091969490051\n","Epoch: 70 | Loss: 0.013862432911992073 | Test loss: 0.03135838359594345\n","Epoch: 80 | Loss: 0.010431952774524689 | Test loss: 0.023772722110152245\n","Epoch: 90 | Loss: 0.006997629068791866 | Test loss: 0.015500170178711414\n"]}]},{"cell_type":"code","source":["print(torch.equal(X_train, X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRHeXJqomi_6","executionInfo":{"status":"ok","timestamp":1757524668840,"user_tz":240,"elapsed":42,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"fa0b66bd-c4a1-4038-8108-6db844ff3a5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["with torch.inference_mode():\n","  y_pred_new = model_0(X_test)"],"metadata":{"id":"F5_EE-v-g2_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dur_GlB9fxGA","executionInfo":{"status":"ok","timestamp":1757524668846,"user_tz":240,"elapsed":3,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"216d3f2e-f8c4-4a8a-8b1c-c24293e93ab1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.6823])), ('bias', tensor([0.3074]))])"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["### Saving a model in PyTorch\n","\n","There are three main methods you should know about for saving and loading models in PyTorch.\n","\n","1. 'torch.save()' - allows you save a PyTorch object in Python's pickle format\n","'torch.load()' - allows you load a saved PyTorch object\n","'torch.nn.Module.load_state_dict()' - this allows to load a model's saved state dictionary"],"metadata":{"id":"WcPi3Jo9sko5"}},{"cell_type":"code","source":["# Saving our PyTorch model\n","from pathlib import Path\n","\n","# 1. Create models directory\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# 2. Create model save path\n","MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","MODEL_SAVE_PATH\n","\n","# 3. Save the model state dict\n","print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n","torch.save(obj=model_0.state_dict(),\n","           f=MODEL_SAVE_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKNla-4osjWw","executionInfo":{"status":"ok","timestamp":1757524668848,"user_tz":240,"elapsed":2,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"5232278f-6bfe-4f6a-855c-dce5c15f37da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to: models/01_pytorch_workflow_model_0.pth\n"]}]},{"cell_type":"markdown","source":["## Loading a Pytorch model\n","\n","Since we saved our model's 'state dict() rather than the entire model, we'll create a new instance of our model class and load the saved 'state dict()' into that."],"metadata":{"id":"tFebG00Ni7HP"}},{"cell_type":"code","source":["model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M19G0s1Ji2Qf","executionInfo":{"status":"ok","timestamp":1757524668853,"user_tz":240,"elapsed":4,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"9be091ff-32d5-4441-9f7c-63500edb6742"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.6823])), ('bias', tensor([0.3074]))])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# To load in a saved state_dict we have to instantiate a new instance of our model class\n","loaded_model_0 = LinearRegressionModel()\n","\n","# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n","loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLwFwowpjl8Y","executionInfo":{"status":"ok","timestamp":1757524668881,"user_tz":240,"elapsed":28,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"1ca82843-da02-4872-a18d-80a42b739287"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["loaded_model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNozQ2-9j-oH","executionInfo":{"status":"ok","timestamp":1757524668882,"user_tz":240,"elapsed":12,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"8800fa94-58db-473b-dff3-d37d4608265e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.6823])), ('bias', tensor([0.3074]))])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Make some predictions with our loaded model\n","loaded_model_0.eval()\n","with torch.inference_mode():\n","  loaded_model_preds = loaded_model_0(X_test)\n","\n","loaded_model_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7VC8iDLkgb3","executionInfo":{"status":"ok","timestamp":1757524668882,"user_tz":240,"elapsed":9,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"c499b9c6-6dd0-4c53-c5b6-ce30fc32d156"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8533],\n","        [0.8669],\n","        [0.8806],\n","        [0.8942],\n","        [0.9078],\n","        [0.9215],\n","        [0.9351],\n","        [0.9488],\n","        [0.9624],\n","        [0.9761]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# Make some models preds\n","model_0.eval()\n","with torch.inference_mode():\n","  y_preds = model_0(X_test)\n","\n","y_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEnf0EE0lYxo","executionInfo":{"status":"ok","timestamp":1757524668883,"user_tz":240,"elapsed":7,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"e7cb1475-ad15-4d5c-c8e7-f72953615686"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8533],\n","        [0.8669],\n","        [0.8806],\n","        [0.8942],\n","        [0.9078],\n","        [0.9215],\n","        [0.9351],\n","        [0.9488],\n","        [0.9624],\n","        [0.9761]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Compare loaded model preds with original model preds\n","y_preds == loaded_model_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34JjOEkjk8ZP","executionInfo":{"status":"ok","timestamp":1757524668894,"user_tz":240,"elapsed":15,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"79704946-71fe-4011-ab26-cf4282d28f99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True],\n","        [True]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["y_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWQU1YkKlFgW","executionInfo":{"status":"ok","timestamp":1757524668895,"user_tz":240,"elapsed":12,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"de201b59-6eff-4273-c9b7-0d9b2f49758a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8533],\n","        [0.8669],\n","        [0.8806],\n","        [0.8942],\n","        [0.9078],\n","        [0.9215],\n","        [0.9351],\n","        [0.9488],\n","        [0.9624],\n","        [0.9761]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["### Putting it all together\n","\n","Let's go back through the steps aboe and see it all in one place\n","\n"],"metadata":{"id":"0avcwCd_mfGV"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import matplotlib.pyplot as plt\n","\n","# Check PyTorch Version\n","torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zEr3O3N3m19P","executionInfo":{"status":"ok","timestamp":1757524668906,"user_tz":240,"elapsed":21,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"8101410f-1d97-4a75-bc2c-6413eeceaeff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0+cu126'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["Create Device-agnostic code.\n","This means if we've got access to a GPU, our code will use it (for potentially faster computing).\n","If no GPU is available, the code will default to using CPU"],"metadata":{"id":"6IYgR0tmnWe3"}},{"cell_type":"code","source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypFA19NXnP52","executionInfo":{"status":"ok","timestamp":1757524671800,"user_tz":240,"elapsed":6,"user":{"displayName":"Ragul Thiyagarajan","userId":"06399568424294317805"}},"outputId":"475ef7c1-b6e5-424a-c608-1ea357296aeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# Create some data using the linear regression formula of y = weight * X + bias\n","weight = .2\n","bias = .8\n","\n","# Create range values\n","start = 0\n","end = 1\n","step = .02\n","\n","# Create X and y (features and labels)\n","X = torch.arange(start, end, step).unsqueeze(dim=1) # without unsqueeze, errors will pop up\n","y = weight * X + bias"],"metadata":{"id":"AStDS98pox5u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Stopped at 7:47 - recreating process"],"metadata":{"id":"wF5lSZ7crFFY"},"execution_count":null,"outputs":[]}]}